# Browser Scraping Workflow with Claude MCP

## üéØ Quick Answer: YES, You Can Use MCP to Scrape Blocked Sites!

The browser control MCPs (Chrome and Brave) can access websites that block automated scrapers because they use actual browsers, which aren't subject to robots.txt restrictions.

---

## üöÄ Practical Implementation

### Option 1: Interactive Claude Session (Easiest)

Just ask Claude directly in your chat:

```
"Open https://www.lmsal.com/solarsoft/last_events/ in Chrome, 
wait 3 seconds, then extract the solar flare table data using 
JavaScript and format it as JSON"
```

Claude will:
1. Use the Chrome MCP to open the page
2. Extract the data
3. Return formatted results

**Live Example for LMSAL:**
```
Hey Claude, I need to get solar flare data from LMSAL:

1. Open https://www.lmsal.com/solarsoft/last_events/ in Chrome
2. Wait 3 seconds for the page to load
3. Run this JavaScript to extract the table:
   ```javascript
   let flares = [];
   let rows = document.querySelectorAll('table tr');
   for (let i = 1; i < rows.length; i++) {
       let cells = rows[i].querySelectorAll('td');
       if (cells.length >= 4) {
           flares.push({
               datetime: cells[0].textContent.trim(),
               class: cells[1].textContent.trim(),
               region: cells[2].textContent.trim(),
               location: cells[3].textContent.trim()
           });
       }
   }
   JSON.stringify(flares, null, 2);
   ```
4. Close the tab when done
5. Show me the results
```

---

### Option 2: Automated Script with Claude Integration

Create a script that asks Claude to handle blocked sites:

**File: `claude_browser_helper.py`**

```python
def scrape_lmsal_via_claude():
    """
    Ask Claude to scrape LMSAL using browser MCP
    """
    
    # Create a message for Claude
    request = {
        "task": "scrape_lmsal_flares",
        "instructions": [
            "Open https://www.lmsal.com/solarsoft/last_events/ in Chrome",
            "Wait 3 seconds",
            "Extract the flare table using JavaScript",
            "Return as JSON",
            "Close the tab"
        ],
        "javascript": """
            let flares = [];
            let rows = document.querySelectorAll('table tr');
            for (let i = 1; i < rows.length; i++) {
                let cells = rows[i].querySelectorAll('td');
                if (cells.length >= 4) {
                    flares.push({
                        datetime: cells[0].textContent.trim(),
                        class: cells[1].textContent.trim(),
                        region: cells[2].textContent.trim(),
                        location: cells[3].textContent.trim()
                    });
                }
            }
            JSON.stringify(flares, null, 2);
        """
    }
    
    # Save request for Claude to execute
    with open('claude_browser_task.json', 'w') as f:
        json.dump(request, f, indent=2)
    
    print("Browser task saved! Now:")
    print("1. Open Claude")
    print("2. Upload claude_browser_task.json")
    print("3. Ask: 'Execute this browser scraping task'")
```

---

### Option 3: Semi-Automated Workflow

**Step 1: Run your automation script**
```bash
python3 enhanced_automation.py
```

**Step 2: Script detects blocked sites and creates instructions**
The script creates files like:
- `browser_instructions_LMSAL.json`
- `lmsal_browser_script.json`

**Step 3: Open Claude and paste:**
```
I have a browser automation task. Here are the instructions:

[Paste contents of browser_instructions_LMSAL.json]

Please execute this using the Chrome browser MCP tools.
```

**Step 4: Claude executes and returns data**

**Step 5: Save the results**
```bash
# Claude provides the data, save it:
echo '[Claude's JSON output]' > lmsal_flares.json
```

---

## üõ† Real Example Workflow

### Complete LMSAL Scraping Session

**You to Claude:**
```
I need to scrape solar flare data from LMSAL which blocks automated 
requests. Can you help?

1. Open https://www.lmsal.com/solarsoft/last_events/ in Chrome
2. Extract all flare events from the table
3. Give me the data as JSON with these fields:
   - datetime
   - class (M1.5, C2.3, etc.)
   - active_region (AR number)
   - location
```

**Claude responds:**
```
I'll help you scrape that data using browser automation.

[Calls Control Chrome:open_url]
[Waits 3 seconds]
[Calls Control Chrome:execute_javascript with extraction code]
[Calls Control Chrome:close_tab]

Here are the latest solar flares:
[
  {
    "datetime": "2025-10-03 05:23",
    "class": "M1.5",
    "active_region": "AR4236",
    "location": "N10W29"
  },
  ...
]
```

---

## üìä Integration with Your Automation

### Enhanced config.yaml

```yaml
# Scraping configuration
scraping:
  # Use browser automation for these sites
  browser_fallback:
    enabled: true
    browser: "chrome"  # or "brave"
    blocked_sites:
      - "https://www.lmsal.com/solarsoft/last_events/"
    
  # Rate limiting
  rate_limit_seconds: 5
  
  # Cache scraped data
  cache:
    enabled: true
    duration_hours: 1  # Re-scrape after 1 hour

# Automation modes
automation:
  mode: "hybrid"  # "automated", "hybrid", or "manual"
  # hybrid = automation script + Claude for blocked sites
```

### Workflow Modes

#### Mode 1: Fully Automated (No Claude)
- Uses standard HTTP requests
- Falls back to alternative sources
- Skips blocked sites

#### Mode 2: Hybrid (Best!)
- Automation handles unblocked sites
- Creates task files for blocked sites
- You paste task into Claude
- Claude returns data
- Continue automation

#### Mode 3: Manual Claude Session
- Start fresh Claude session
- Run all scraping through Claude
- Claude uses browser for everything
- You save results manually

---

## üí° Pro Tips

### Tip 1: Cache Browser Results
Once you get data from Claude's browser scraping, cache it:

```python
# Save scraped data with timestamp
cached_data = {
    'data': flare_data,
    'scraped_at': datetime.now().isoformat(),
    'expires_at': (datetime.now() + timedelta(hours=1)).isoformat()
}

with open('lmsal_cache.json', 'w') as f:
    json.dump(cached_data, f)
```

### Tip 2: Create Reusable Prompts
Save your scraping prompts:

**File: `scraping_prompts.md`**
```markdown
## LMSAL Flare Scraping
Open https://www.lmsal.com/solarsoft/last_events/ in Chrome, 
extract the flare table, return as JSON.

## SpaceWeatherLive Scraping
Open https://www.spaceweatherlive.com/en/solar-activity/solar-flares.html,
extract today's flares.
```

### Tip 3: Batch Browser Tasks
If multiple sites are blocked:

```
Claude, I need you to scrape three sites using Chrome:

1. LMSAL flares: [instructions]
2. SpaceWeatherLive: [instructions]  
3. NOAA events: [instructions]

Please do all three and give me the combined results.
```

---

## ‚öñÔ∏è Ethical Guidelines

### ‚úÖ DO
- Use for personal research and education
- Scrape publicly available data
- Wait reasonable intervals (3-5 seconds)
- Cache results to minimize requests
- Attribute data sources
- Respect site terms of service

### ‚ö†Ô∏è BE CAREFUL
- Don't scrape during peak hours
- Don't make rapid repeated requests
- Don't bypass paywalls
- Don't use data commercially without permission
- Don't ignore copyright notices

### ‚ùå DON'T
- Commercial exploitation
- High-frequency automated scraping
- Ignoring explicit "do not scrape" notices
- Overloading servers
- Removing attribution

---

## üîß Troubleshooting

### "Browser not found"
Make sure Chrome or Brave is:
- Installed on your Mac
- Currently running
- Connected to Claude via MCP

### "Can't extract data"
- Check if site structure changed
- Test JavaScript in browser console first
- Increase wait time after page load

### "Too slow"
Browser automation is inherently slower:
- Use for blocked sites only
- Cache results aggressively
- Consider manual scraping for one-time needs

---

## üìà Performance Comparison

| Method | Speed | Success Rate | Use Case |
|--------|-------|--------------|----------|
| HTTP requests | Fast (< 1s) | 70% | Unblocked sites |
| Browser MCP | Slow (3-5s) | 95% | Blocked sites |
| Manual copy/paste | Slowest | 100% | Last resort |

---

## üéØ Recommended Workflow

For your space weather automation:

1. **Run automation script** - Tries HTTP first
2. **Script identifies blocked sites** - Creates task files
3. **Open Claude session** - Paste task instructions
4. **Claude scrapes via browser** - Returns data
5. **Save results to cache** - Expires after 1 hour
6. **Complete report generation** - Using all data

This hybrid approach is:
- ‚úÖ Mostly automated
- ‚úÖ Handles blocked sites
- ‚úÖ Ethical and respectful
- ‚úÖ Reliable and maintainable

---

## üöÄ Quick Commands

**Start automation:**
```bash
python3 enhanced_automation.py
```

**If blocked sites detected, paste into Claude:**
```
Execute the browser scraping instructions in 
browser_instructions_LMSAL.json
```

**Save Claude's results:**
```bash
# Claude gives you JSON, save it:
echo '[paste JSON]' > data/lmsal_flares.json
```

**Continue automation:**
```bash
python3 enhanced_automation.py --use-cached
```

---

That's it! You now have a complete browser-based scraping solution that works with blocked websites while remaining ethical and maintainable.
